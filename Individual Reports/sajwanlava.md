# SWEN422 Assignment 2 : Large Group Project (Mini-Game)

## Team 19 (VRtigo) : Individual Report

**Lavanya Sajwan - 300381661**

## BACKGROUND

#### Introduction

This assignment aims for the team to design a mini-game in which players can provide a range of interaction to explore the multiple features of the interface. The game should provide the minimum features for game experience and support aspects of the Self Determination Theory.

#### Description of the System

Team 19 designed a puzzle and time trial oriented mini-game using Unity. The game enables users to problem solve under a time pressure component. It provides an in-world, immersive experience with the players finishing the levels in the first-person point of view. End-users can place portals on white surfaces using left and right triggers and can move through the portals to navigate through the levels. Portals can be rebound off grey surfaces in order to increase the creative manoeuvrability through the puzzles.

The mini-game requires and HTC Vive headset in order for users to play. Players can move in-world by moving in their physical environment, or by using the left trackpad. However, moving in the physical world is not recommended as that increases the risk of any physical incidents. The player can rotate themselves in the virtual environment by clicking left or right on the trackpad of the controller or by turning their head. As mentioned above, portals are formed by launching them with the use of pressing on the left and right trackpads. Menu buttons in the virtual world are also able to be interacted with by the use of the portal projectiles aimed at them.

#### Overall Presentation

As briefly touched upon in the subsection above, the mini-game has dark and light surfaces. Users can fire portal projectiles at light surfaces in order for them to form. Alternatively, portals are unable to be invoked on dark surfaces, and these can be used as rebounding surfaces.

Portals are blue and orange, and arbitrary shapes were set on in the virtual environment that was able to be interacted with by the use of portals.

A green circle represents the goal.

A demonstration video can be found [here](https://www.youtube.com/watch?v=ND6rRSEH9pA&feature=youtu.be).

## JUSTIFICATION OF DESIGN

VRtigo decided to use a VR (virtual reality) system for our mini-game because not only do members of the team have an extreme interest for VR systems and gaming, it also provides users with the most increased interaction with the game compared to other interfaces. Users are within the world and have an even more attuned focus on the goal of the levels. The team felt that having a more interactive mini-game was advantageous as while the levels can currently be classified as simple, the use of VR in first-person point-of-view increases the likeability of the game.

The team wanted to have multiple player profiles associated with scores on a leaderboard to match our player types more precisely. However, we also wanted the game to be played one player at a time, which is also characteristic specific to VR. The team took massive inspiration from the famous game 'Portal'. Our game idea was puzzle-based, which calls for more focused attention and is another feature acquired by the VR interface.

Past the selection of the VR interface, a lot of the main design decisions were influenced by the awareness that vertigo and motion-sickness have quite a high risk of being induced in VR. Therefore our decisions were made to reduce this risk. The original game has portals which act as 'gateways' and, while we did initially try this type of design, the team had some difficulties implementing it. We then also realised that that type of design might be disorienting for many players in a VR environment. Therefore, we settled on our portals imitating more of a teleportation door by changing the environment around the player to match the other portal.

The objects in the world that held the most importance to the player had a very distinct colour in order to identify them in the virtual world quickly. These such objects were the two portals and the end goal. The portals were chosen to be blue and orange, as they are complementary colours on the colour wheel [[1]](https://www.canva.com/colors/color-wheel/) and are bold thus easily visible, making navigation to them effortlessly attainable. The end case for a level is the green goal circle on the ground. This colour was chosen once again as the colour is bright for a user to locate with ease. Green is also a colour often attributed to reward [[2]](https://www.bourncreative.com/meaning-of-the-color-green/) and seemed like the right colour to use to evoke feelings of achievement. VR is not often friendly to those who wear glasses. However, through using distinct colours, we were able to get those who usually wear glasses to play the game without them. I can personally attest to this as my eyesight is relatively impaired, and I was still able to complete the tutorial level without vision-related difficulty. These colours are also quite different as to minimise the adverse effects on anyone with colour-blindness or colour- deficiency.

As to not to distract the player from vital objects and actions for gameplay, the rest of the immediate environment was quite pallid. Portals were able to be cast onto lighter 'white' walls and were not able to on darker 'grey' walls or the maroon floor.

Much thought went to the menu, and this was eventually settled upon being in-world. Following several team discussions, we felt that as it is the first experience of the mini-game that users will have, having an interactive menu that reacts similarly to the normal game-play will engage users from the beginning. Having a menu that acts like the game is beneficial in introducing the idea and control even before going through the tutorial level.

The gameplay was designed by focusing on specific player archetypes. These helped shape our decisions made while planning and developing the mini-game. These included the player motivation, game mechanics, scope, complexity and the visuals described above. The team decided that the end-product will be a mini-game conceived around Bartle's player types for gamification; precisely the types "Killer" and "Achiever". Killers want to achieve success by competing against others, while achievers are motivated by their successes. The design decisions anchoring to the types of the psychology of our players made the leaderboard idea described earlier come to fruition.

Future player engagement with the game was considered using the Self Determination Theory [[3]](https://en.wikipedia.org/wiki/Self-determination_theory). The final design of our mini-game fit under the three fundamental needs; agency, competence and relatedness. Players were able to choose what level they would like to play and thus the difficulty of the puzzle they would like to complete, therefore, managing aspects of agency. Competence and relatedness were also planned for by the use of a scoreboard. The fastest time on the scoreboard displayed to the players how well they were doing (competence), and it also provided a way for players to challenge their peers (relatedness).

Overall, this mini-game displayed both the types of motivation; extrinsic and intrinsic. However, while the player was able to achieve extrinsic motivation from their social group by maintaining a high score, the dominant motivation was that of the intrinsic type. This was because the mini-game designed was ultimately a planning game where each level was a different puzzle. This shows aspects of intrinsic motivation as ultimately, the players found the most enjoyment in solving the levels, which was also supported in some post-test questionnaire responses.

## CONTRIBUTIONS

During this project, the team decided to follow the animal roles for project management. As this group project ran throughout a busy period at university, the animal avatars helped with our group organisation and communication.

I held the facilitator, 'Rabbit' role in the team. In my opinion, I performed well in this role. I would continuously initiate conversations about the project in our communication channel and also organise any meeting rooms needed. While I did not have the sole responsibility of the issue board, I was one of the critical maintainers of it.

Another aspect of this role is the need for affiliation, and a lot of my work was entirely collaborative. I would often take up the aspect of the owl by making sure objectives were met and also the puppy as I would support my teammates' ideas and wanted to help develop and add to them.

Vital responsibilities of this role included providing the resources to achieve goals. This was done by asking any questions needed to clear up internal group confusion, and also answering questions that any of my teammates would have. I would also prompt conversations about the group progress and started off planning for our progress presentation. My most significant responsibility for this role was the entire user testing process.

I am not the strongest programmer, and therefore a lot of the work I completed was based on documentation and evaluations. However, when the project was still in the early stages of programming, I did peer-program alongside Brandon in the initial portal iterations.

My contributions included:

- Communications with the team; keeping everyone up-to-date with any changes/adaptations if away.
- Maintaining internal deadlines by ensuring every team member was sharing knowledge and had the resources needed to complete tasks.
- Organising meetings and booking any rooms if necessary.
- Had the facilitator for the usability testing process which involved communicating with the test participants, and my team.
- Writing [usability documentation](https://gitlab.ecs.vuw.ac.nz/swen422-2019-a2/t19/swen422-assignment2/tree/master/User%20Testing) (Usability test plan, usability tasks, pre/post-test questionnaires, and the usability report)
- Writing justification of [player types](https://gitlab.ecs.vuw.ac.nz/swen422-2019-a2/t19/swen422-assignment2/blob/master/Documentation/Player%20Type.md)
- Writing a share of the [group analysis](https://gitlab.ecs.vuw.ac.nz/swen422-2019-a2/t19/swen422-assignment2/blob/master/Documentation/Group%20Analysis.md)
- Basic level ideation
- Initial portal peer-programming
- I would often be a tester for the internal team tests.

The teams' issue board can be found [here](https://gitlab.ecs.vuw.ac.nz/swen422-2019-a2/t19/swen422-assignment2/-/boards).

## INTERPRETATION OF THE RESULTS OF THE EVALUATION

Participants were chosen from the pool of 400 level ECS students or anyone else enrolled in the course that did not immediately fall into that category. The players had to do a pre and post-test questionnaire and were informed that they were able to request the information to be released to them if they wanted. Given that there was a small group of students to choose for testing; the participants were chosen at random of who was there on the day and no name information was collected.

The pre-test questionnaire collected demographic information from the testers, so the team was able to build future user profiles, and the post-test questionnaire provided the team with the means to gauge satisfaction. Testing was run in the same room to limit any unintentional external reasons for changes to the user's response. Users also were not able to see the testing screen to avoid them planning any of the puzzles beforehand, which would skew our average times.

The team did two rounds of usability testing involving the prototype being adapted between both of the groups. During the testing, the team recorded the time taken to complete tasks, the completion rate, the error-free rate and any observations we had. We also collected pre and post-test responses from the testers. From all these notes and documentation, the team collected problems. These problems were rated based on the impact on the player and frequency of the problem occurring. From there, the problems were associated with a severity number; one being the highest severity and four being the lowest.

After the first set of testing, the [results](https://gitlab.ecs.vuw.ac.nz/swen422-2019-a2/t19/swen422-assignment2/blob/master/User%20Testing/Usability%20Test%20Report.md#results) of the main feedback collated showed that there were problems in finding how to complete the level or tutorial. However, the team decided to collectively disregard that feedback as we felt it was more focused on the gameplay and the difficulties individual players had with solving the puzzles. A majority of the other problems gathered showed that there were significant issues with certain aspects of the mini-game still inducing some VR related sickness. From the beginning of the project, this was an issue we wanted to mitigate as much as possible and thus these were the issues we fixed between the two usability testing groups. These issues either had a severity issue of 1or 3. Another minor feedback that was obtained was that the game needed to be more immersive in order to feel complete. In response to this, the team implemented the use of audio to be associated with actions in the game.

Having a second usability test was beneficial to the team as, while we fixed quite a few issues between the tests, the second group had come up with some vastly different feedback. These were also associated more with the user experience, which was very helpful for the team. After this testing, a lot of the problems had very high severity levels of one or two and revolved around aiming and context. This was also because a lot of the usability testers came upon the same issues with our mini-game.

An interesting problem that was picked up by both groups was that the green goal took too long to register level completion. Another problem that was highlighted in both was that the colour difference between the grey and the white was too slight for the user to be able to differentiate between them easily. This severity level increased after the second usability test from a 3 in the original version to a 2 in the second as more players commented on this issue compared to the first. We also had a colour-deficient tester in the second one who eventually had a critical failure with this test task as he could not tell the difference.

It was identified that users had aiming issues in the virtual environment in the first user testing. While we realised this was an issue and rated it a severity of one, the group overall had an error-free rate of 80%; we, therefore, decided that it did not require significant change between test groups. However, this was an issue with the second group who had an error-free rate of only 42% with one player firing at the wrong level 4 times before choosing the correct one on their fifth attempt. With this issue so prevalent in this test group, the feedback obtained also had suggestions for players being able to exit levels when within them.

The Usability Testing Documents can be found [here](https://gitlab.ecs.vuw.ac.nz/swen422-2019-a2/t19/swen422-assignment2/blob/master/User%20Testing/).

## LIMITATIONS OF THE EVALUATION

The team managed to run two rounds of usability testing, with the mini-game prototype bettered between testing groups. However, due to time constraints, we had to do these rounds of testing within one day. As a result, we were not able to fix as many of the issues of our design, and some of the problems obtained from the second group test were already known to the team.

Another limitation once again contrived from the lack of time was that after the second round of usability testing, we were unable to implement the changes needed to solve the problems that users had. If given this project again, and having a facilitator role, I would prompt the team to have testing earlier in the project life cycle. However, I do also acknowledge that this would pose some difficulty, given that we each had many deadlines and exams around this time.

A group-level limitation from our evaluation is that even though we had used a severity numbering scale to sort through our problems in order to tackle them most effectively, the team seemed to ignore it. We instead focused on the problems which had an error-free rate lower than 100%. A suggestion for the future would be to either strictly follow the severity scale, or, disregard the use of a severity scale and instead make changes to the mini-game based on the error-free rate.

While running the tests, users were unable to see the screen to avoid any familiarity with the game before evaluation. However, group one's participants were allowed inside the room while another member was testing. The waiting participants were then able to here the questions before actually interacting with the game, and this could have affected whether our results were accurate or not. This could also be the reason the differences between the tasks in both tests had very different error-free rates. For example, the task to "Select Tutorial from the Menu", had an error-free rate of 80% in the first group, and had 42% in the second group.

The testing also developed an unintentional bias as the results collected and subsequently collated in the [usability test plan](https://gitlab.ecs.vuw.ac.nz/swen422-2019-a2/t19/swen422-assignment2/blob/master/User%20Testing/Usability%20Test%20Report.md#results) was that of mostly males. This would mean that if we were to develop a properly finished product with all the evaluation problems solved, there would be a risk of the game having a gender bias. Age bias is also a risk as every single one of our testing players were in the 21-30 age range. However, this was also due to the limitations proposed to us in the brief as all individuals who would usability test had to be a 4th year ECS (Engineering and Computer Science) students or any other individual enrolled in the course.

When doing testing, as mentioned in the section above, there was some feedback as being unsure of how each physical, real-world action was translated as a virtual-world action. Users also struggled in understanding the context of the game. This was an error on the teams' behalf as we were focused on the players testing for us without any pre-conceived knowledge. This was so we would get an impartial reaction to the tasks. We had also assumed that most people would already know the game 'Portal' and this would be enough for them to understand how to play. In hindsight, if we did want an impartial reaction, we should have provided a means for the user to obtain information within the game. This could have been in the form of a starting-of-the-game storyline to introduce the objective and help messages through the tutorial level.

## PROPOSED IMPROVEMENTS TO THE GAME

As mentioned above, many users found it challenging to understand the overarching concept of the game. An improvement for the mini-game would be to add in the game objective description to the menu, and consequently help messages in the tutorial level. A tester in group two mentioned that it seemed disconcerting having us talk to them and having them talking within the game, so perhaps these messages could be in the form of an audio message. This would give the mini-game another level of interaction with the user. However, this could potentially cause issues for users with hearing deficiency and make the game more challenging to use.

While the game designed was a puzzle-game, which relies on the players' ability to problem-solve, it was also a skill game in the sense that players had to rebound their projectile creatively in order to reach the end-goal of the level. What users found extremely difficult was the control they had over this, as there was no way to scope the pathway of the fired portal. This resulted in lots of misfires and players sometimes chose unintended levels. Therefore, the addition of an aim assist would be extremely beneficial. This would be a 'laser' stream coming from the virtual handset, and each colour stream would be attributed to the portal colours; orange and blue. Another addition to this would be in the case of a player continually choosing the wrong level with the use of an aiming scope; there should be a way to be able to either go back to the main menu from within the game without having to repeat the level, or having the facilitators manually change the level from within the Unity editor.

Another high severity issue that should be resolved will be the design around the goal. Many players found that the green goal was not prominent enough and that it was unclear what it stood for as it was not significant or bold. It also took too long to register that a player was on it and as people are relatively impatient, many testers would walk out of it, and the goal timer would restart once again. To fix these issues I would suggest the addition of a virtual world sign near the goal circle on the floor which states 'FINISH', and to decrease the goal timer from 3 seconds to half a second.

Overall, the vast majority of users enjoyed the mini-game, and due to this, we had a lot of individuals willing to test for us. As a result, we were able to engage with users and receive a lot of feedback and observations. I believe that the mini-game currently has a few steps to go before it becomes a strong product but, with the collated suggestions above, I believe it could become even more enjoyable for users to interact with.

## BIBLIOGRAPHY

1. Color wheel - color theory and calculator: Canva Colors. (n.d.). Retrieved October 25, 2019, from https://www.canva.com/colors/color-wheel/.
2. BournCreative, J., & Digital Strategist Â· WordPress. (2016, June 4). Meaning of The Color Green |. Retrieved October 26, 2019, from https://www.bourncreative.com/meaning-of-the-color-green/.
3. Self-determination theory. (2019, October 19). Retrieved October 27, 2019, from https://en.wikipedia.org/wiki/Self-determination_theory.

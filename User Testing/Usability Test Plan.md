## Usability Test Plan

### Overview

This document describes a test plan for conducting a usability test during the development of VRtigo team mini-game. The goals of usability testing include establishing a baseline of user performance, establishing and validating user performance measures, and identifying potential design concerns to be addressed in order to improve the efficiency, productivity, and end-user satisfaction.
The usability test objectives are:

To determine design inconsistencies and usability problem areas within the user interface and content areas. Potential sources of error may include:

- Navigation errors – failure to locate functions, excessive hand movements or touches to complete a function, failure to follow recommended screen flow.
- Presentation errors – failure to locate and properly act upon desired information in screens, selection errors due to labelling ambiguities, and motion-sickness inducing elements.
- Control usage problems – interaction with virtual objects lagging, and rendering issues when users go through portal.

Exercise the application or web site under controlled test conditions with representative users. Data will be used to access whether usability goals regarding an effective, efficient, and well-received user interface have been achieved.
Establish baseline user performance and user-satisfaction levels of the user interface for future usability evaluations.

This mini-game can be used by many people with a range of characteristics. To ensure relevant feedback for our prototype, we have acquired people from many user groups for our usability testing. The testing will take place in a lab on Monday 21st of October.

### Executive Summary

The usability tests involve participants who represent an interest in games and/or virtual reality and will be going through specific tasks related to set game use-cases, in order to gather feedback on our prototype.

### Methodology

**The detailed process has**:

Number of participants: 10+ <br>
Location of testing:Co332 <bbr>
Tools used for user interaction: We will use laptops to carry out the testing and users will use the Vive headset and controllers, and will have a vomit bag available to them in-the-case of extreme vertigo or motion sickness. 

**Measures collected:**:

*  Time taken to complete scenario's
*  Any observational notes
*  Users pre-test and post-test opinions

**Demographic information:**

* Gender
* Age group
* Current relevant behaviours (what games they might play and in what sort of environment)
* Interests and priorities
* Any other traits of interest


**Satisfaction assessment:**

* post-test questionnaire
* time taken to complete a task
* any other comments made while or after completing a task


Suggestions for improvement are collected in our post-test questionnaire

### Ethics

This usability study has run under the considerations of the assignment brief and participants are either enrolled in this course or are other 400 level students. It has recieved Human Ethics Committee permission — under application 25862.

### Participants

Our test participants are gained by asking other students to test our system. They are perfectly eligible participants for our mini game as they are adults enrolled in this course/are 400 level students and have an interest in games and game design. The participants will attempt to complete a range of tasks based on in-game scenarios.

### Training

Participants will not be given any specific training for our mini-game as many of the features will be somewhat familiar from various other applications. We want our game to be very intuitive and easy to navigate and learn, so the team will not provide any formal training to prepare them for testing. This is so the team will be able to obtain a natural response and feedback. The participants will receive an overview of the usability test procedures and equipment.

### Procedure

Participants will take part in the usability test in CO332, in the Cotton building, Victoria University of Wellington, Kelburn. A VR headset and controller will be used with the software in this room. The participants interaction with the prototype will be monitored by the facilitators and note takers and data loggers will silently monitor the sessions within the room.

### Roles

The roles involved in a usability test are as follows. An individual may play multiple roles and tests may not require all roles.


*  Trainer - Nick (Provide training overview prior to usability testing)
*  Facilitator - Lavanya (Provides an overview of the study to participants, defines usability and purpose of usability testing to participants, assists in conducting the participant and observer debriefing sessions, responds to participant's requests for assistance)
*  Data Logger - Rachel (Records participants time-on-task metrics)
*  Test Observer/Silent Observer - Brandon/Cameron (Assists the data logger in identifying problems, concerns, coding bugs, and procedural errors. Serve as note takers)

### Usability Tasks

The usability tasks are derived from test scenarios developed from use cases. Due to the range and extent of the functionality provided by the mini-game, and the short time for which each participant will be available, the tasks are the most common and relatively complex of available functions. The tasks are identical for all participants of a given user role in the study.

### Usability test tasks

Usability Metrics
Usability metrics refers to user performance measured against specific performance goals necessary to satisfy usability requirements. Task completion success rates, adherence to dialogue scripts, error rates, and subjective evaluations will be used. Time-to-completion of scenarios will also be collected.

Task Completion
Each task will require, or request, that the participant inputs specific actions or data that would be used in the course of a typical task. The scenario is completed when the participant indicates the scenario's goal has been obtained (whether successfully or unsuccessfully) or the participant requests and receives sufficient guidance as to warrant scoring the scenario as a critical error.

Critical Errors
Critical errors are deviations at completion from the targets of the scenario. Obtaining or otherwise reporting of the wrong data value due to participant work flow is a critical error. Participants may or may not be aware that the task goal is incorrect or incomplete.
In general, critical errors are unresolved errors during the process of completing the task or errors that produce an incorrect outcome.

Non-critical Errors
Non-critical errors are errors that are recovered from by the participant or, if not detected, do not result in processing problems or unexpected results. Although non-critical errors can be undetected by the participant, when they are detected they are generally frustrating to the participant.
These errors may be procedural, in which the participant does not complete a scenario in the most optimal means (e.g., excessive steps and keystrokes). These errors may also be errors of confusion (ex., initially selecting the wrong function, using a user-interface control incorrectly such as attempting to edit an un-editable field).
Non-critical errors can always be recovered from during the process of completing the scenario. Exploratory behaviour, such as opening the wrong menu while searching for a function, will be coded as a non-critical error.

Subjective Evaluations
Subjective evaluations regarding ease of use and satisfaction will be collected via questionnaires, and during debriefing at the conclusion of the session. The questionnaires will utilise free-form responses and rating scales. The scales range from 1 to 5 - 1 being bad/unsatisfactory/low, and 5 being good/satisfactory/high.

Scenario Completion Time (time on task)
The time to complete each scenario, not including subjective evaluation durations, will be recorded.

Usability Goals
The usability goals for the mini-game include:

Completion Rate
Completion rate is the percentage of test participants who successfully complete the task without critical errors. A critical error is defined as an error that results in an incorrect or incomplete outcome. In other words, the completion rate represents the percentage of participants who, when they are finished with the specified task, have an "output" that is correct. Note: If a participant requires assistance in order to achieve a correct output then the task will be scored as a critical error and the overall completion rate for the task will be affected.
A completion rate of 86% (6 out of 7 test participants) is the goal for each task in this usability test.

Error-free rate
Error-free rate is the percentage of test participants who complete the task without any errors (critical or non-critical errors). A non-critical error is an error that would not have an impact on the final output of the task but would result in the task being completed less efficiently.
An error-free rate of 86% (6 out of 7 test participants) is the goal for each task in this usability test.

Time on Task (TOT)
The time to complete a scenario is referred to as "time on task". It is measured from the time the person begins the scenario to the time he/she signals completion.

Subjective Measures
Subjective opinions about specific tasks, time to perform each task, features, and functionality will be surveyed. At the end of the test, participants will rate their satisfaction with the overall system. Combined with the interview/debriefing session, this data is used to assess the attitudes of the participants.

Problem Severity
To prioritize recommendations, a method of problem severity classification will be used in the analysis of the data collected during evaluation activities. The approach treats problem severity as a combination of two factors - the impact of the problem and the frequency of users experiencing the problem during the evaluation.

Impact
Impact is the ranking of the consequences of the problem by defining the level of impact that the problem has on successful task completion. There are three levels of impact:

High - prevents the user from completing the task (critical error)
Moderate - causes user difficulty but the task can be completed (non-critical error)
Low - minor problems that do not significantly affect task completion (non-critical error)

Frequency
Frequency is the percentage of participants who experience the problem when working on a task.

High: 30% or more of the participants experience the problem (3 or more test participants)
Moderate: 14% - 29% of participants experience the problem (2 out of 7 test participants)
Low: 14% or fewer of the participants experience the problem (1 out of 7 test participants)

Problem Severity Classification
The identified severity for each problem implies a general benefit for resolving it, and a general risk for not addressing it, in the next release.

Severity 1 - High impact problems that often prevent a user from correctly completing a task. They occur in varying frequency and are characteristic of calls to the Help Desk. The benefit for resolution is typically exhibited in fewer Help Desk calls and reduced redevelopment costs.

Severity 2 - Moderate to high-frequency problems with moderate to low impact are typical of erroneous actions that the participant recognizes needs to be undone. Benefit for resolution is typically exhibited in reduced time on task and decreased training costs.

Severity 3 - Either moderate problems with low frequency or low problems with moderate frequency; these are minor annoyance problems faced by a number of participants. The benefit for resolution is typically exhibited in reduced time on task and increased data integrity.

Severity 4 - Low impact problems faced by few participants; there is low risk to not resolving these problems. The benefit for resolution is typically exhibited in increased user satisfaction.

Reporting Results
The Usability Test Report will be provided at the conclusion of the usability test. It will consist of a report and/or a presentation of the results; evaluate the usability metrics against the pre-approved goals, subjective evaluations, and specific usability problems and recommendations for resolution. The recommendations will be categorically sized by development to aid in the implementation strategy.

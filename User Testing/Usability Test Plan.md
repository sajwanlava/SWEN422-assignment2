## Usability Test Plan

### Authors

### Overview

This document describes a test plan for conducting a usability test during the development of VRtigo team minigame. The goals of usability testing include establishing a baseline of user performance, establishing and validating user performance measures, and identifying potential design concerns to be addressed in order to improve the efficiency, productivity, and end-user satisfaction.
The usability test objectives are:

To determine design inconsistencies and usability problem areas within the user interface and content areas. Potential sources of error may include:

- Navigation errors – failure to locate functions, excessive keystrokes or touches to complete a function, failure to follow recommended screen flow.
- Presentation errors – failure to locate and properly act upon desired information in screens, selection errors due to labelling ambiguities.
- Control usage problems – improper toolbar or entry field usage.

Exercise the application or web site under controlled test conditions with representative users. Data will be used to access whether usability goals regarding an effective, efficient, and well-received user interface have been achieved.
Establish baseline user performance and user-satisfaction levels of the user interface for future usability evaluations.

This minigame can be used by many people with a range of characteristics. To ensure relevant feedback for our prototype, we have acquired people from many user groups for our usability testing. The testing will take place in a lab on INSERT WHEN.

### Executive Summary

The usability tests involve participants who represent our personas going through specific tasks related to our scenario use cases, in order to gather feedback on our prototype.

### Methodology

The detailed process has

Number of participants:
Location of testing:
Tools used for user interaction: We used pen, paper and a laptop to carry out this testing.
Measures collected

Demographic information

Identity within the university (student/lecturer/tutor, undergraduate/postgraduate, domestic/international)
Gender
Age group
Current relevant behaviours (what games they might play and in what sort of environment)
Interests and priorities

Satisfaction assessment

post-task questionnaire
post-test questionnaire
time taken to complete a task
any other comments made while or after completing a task

Suggestions for improvement are collected in our post-test questionnaire

### Ethics

This usability study has been assessed under Victoria University of Wellington's Human Ethics Committee with approval number: INSERT THE NUMBER

### Participants

<!-- Our test participants are gained through and agreement with another group doing a different system to test their system if they test our system. They are perfectly eligible participants for our system because our web application is a study organiser, designed for primarily students, and all of our participants are students. We have also asked a tutor and a lecturer to be participants because our personas cover these, and our app will be used by these people.
The participants will attempt to complete 21-22 tasks from the scenarios described in the scenario section. -->

### Training

<!-- Participants will not be given any specific training for our web application as many of the features will be somewhat familiar from various other applications, just not in all the same place like this. We want our system to be very intuitive and easy to navigate and learn so we won't do any formal training to prepare them for testing, in order to get the most natural response and feedback. The participants will receive an overview of the usability test procedure, equipment and software. -->

### Procedure

<!-- Participants will take part in the usability test at Room 242b, Cotton building, Victoria University of Wellington, Kelburn. A laptop with the web application prototype and supporting software will be used in this meeting room. The participant’s interaction with the prototype will be monitored by the facilitator 🐰 seated in the same office. Note takers 🦉 and data logger(s) will silently monitor the sessions within the room.
Facilitator brief -->

### Roles

The roles involved in a usability test are as follows. An individual may play multiple roles and tests may not require all roles.

Trainer -

Provide training overview prior to usability testing

Facilitator -

Provides an overview of the study to participants
Defines usability and purpose of usability testing to participants
Assists in conducting the participant and observer debriefing sessions
Responds to participant's requests for assistance

Data Logger -

Records participant’s actions and comments

Test Observers -

Silent observer

Assists the data logger in identifying problems, concerns, coding bugs, and procedural errors.

Serve as note takers

### Usability Tasks

The usability tasks are derived from test scenarios developed from use cases. Due to the range and extent of the functionality provided in the application or Web site, and the short time for which each participant will be available, the tasks are the most common and relatively complex of available functions. The tasks are identical for all participants of a given user role in the study.

### Usability test tasks

Usability Metrics
Usability metrics refers to user performance measured against specific performance goals necessary to satisfy usability requirements. Scenario completion success rates, adherence to dialog scripts, error rates, and subjective evaluations will be used. Time-to-completion of scenarios will also be collected.

Scenario Completion
Each scenario will require, or request, that the participant inputs specific actions or data that would be used in the course of a typical task. The scenario is completed when the participant indicates the scenario's goal has been obtained (whether successfully or unsuccessfully) or the participant requests and receives sufficient guidance as to warrant scoring the scenario as a critical error.

Critical Errors
Critical errors are deviations at completion from the targets of the scenario. Obtaining or otherwise reporting of the wrong data value due to participant workflow is a critical error. Participants may or may not be aware that the task goal is incorrect or incomplete.
In general, critical errors are unresolved errors during the process of completing the task or errors that produce an incorrect outcome.

Non-critical Errors
Non-critical errors are errors that are recovered from by the participant or, if not detected, do not result in processing problems or unexpected results. Although non-critical errors can be undetected by the participant, when they are detected they are generally frustrating to the participant.
These errors may be procedural, in which the participant does not complete a scenario in the most optimal means (e.g., excessive steps and keystrokes). These errors may also be errors of confusion (ex., initially selecting the wrong function, using a user-interface control incorrectly such as attempting to edit an un-editable field).
Noncritical errors can always be recovered from during the process of completing the scenario. Exploratory behaviour, such as opening the wrong menu while searching for a function, will be coded as a non-critical error.

Subjective Evaluations
Subjective evaluations regarding ease of use and satisfaction will be collected via questionnaires, and during debriefing at the conclusion of the session. The questionnaires will utilise free-form responses and rating scales. The scales range from 1 to 5 - 1 being bad/unsatisfactory/low, and 5 being good/satisfactory/high.

Scenario Completion Time (time on task)
The time to complete each scenario, not including subjective evaluation durations, will be recorded.

Usability Goals
The usability goals for the minigame include:

Completion Rate
Completion rate is the percentage of test participants who successfully complete the task without critical errors. A critical error is defined as an error that results in an incorrect or incomplete outcome. In other words, the completion rate represents the percentage of participants who, when they are finished with the specified task, have an "output" that is correct. Note: If a participant requires assistance in order to achieve a correct output then the task will be scored as a critical error and the overall completion rate for the task will be affected.
A completion rate of 86% (6 out of 7 test participants) is the goal for each task in this usability test.

Error-free rate
Error-free rate is the percentage of test participants who complete the task without any errors (critical or non-critical errors). A non-critical error is an error that would not have an impact on the final output of the task but would result in the task being completed less efficiently.
An error-free rate of 86% (6 out of 7 test participants) is the goal for each task in this usability test.

Time on Task (TOT)
The time to complete a scenario is referred to as "time on task". It is measured from the time the person begins the scenario to the time he/she signals completion.

Subjective Measures
Subjective opinions about specific tasks, time to perform each task, features, and functionality will be surveyed. At the end of the test, participants will rate their satisfaction with the overall system. Combined with the interview/debriefing session, this data is used to assess the attitudes of the participants.

Problem Severity
To prioritize recommendations, a method of problem severity classification will be used in the analysis of the data collected during evaluation activities. The approach treats problem severity as a combination of two factors - the impact of the problem and the frequency of users experiencing the problem during the evaluation.

Impact
Impact is the ranking of the consequences of the problem by defining the level of impact that the problem has on successful task completion. There are three levels of impact:

High - prevents the user from completing the task (critical error)
Moderate - causes user difficulty but the task can be completed (non-critical error)
Low - minor problems that do not significantly affect task completion (non-critical error)

Frequency
Frequency is the percentage of participants who experience the problem when working on a task.

High: 30% or more of the participants experience the problem (3 or more test participants)
Moderate: 14% - 29% of participants experience the problem (2 out of 7 test participants)
Low: 14% or fewer of the participants experience the problem (1 out of 7 test participants)

Problem Severity Classification
The identified severity for each problem implies a general benefit for resolving it, and a general risk for not addressing it, in the next release.

Severity 1 - High impact problems that often prevent a user from correctly completing a task. They occur in varying frequency and are characteristic of calls to the Help Desk. The benefit for resolution is typically exhibited in fewer Help Desk calls and reduced redevelopment costs.

Severity 2 - Moderate to high-frequency problems with moderate to low impact are typical of erroneous actions that the participant recognizes needs to be undone. Benefit for resolution is typically exhibited in reduced time on task and decreased training costs.

Severity 3 - Either moderate problems with low frequency or low problems with moderate frequency; these are minor annoyance problems faced by a number of participants. The benefit for resolution is typically exhibited in reduced time on task and increased data integrity.

Severity 4 - Low impact problems faced by few participants; there is low risk to not resolving these problems. The benefit for resolution is typically exhibited in increased user satisfaction.

Reporting Results
The Usability Test Report will be provided at the conclusion of the usability test. It will consist of a report and/or a presentation of the results; evaluate the usability metrics against the pre-approved goals, subjective evaluations, and specific usability problems and recommendations for resolution. The recommendations will be categorically sized by development to aid in the implementation strategy.
